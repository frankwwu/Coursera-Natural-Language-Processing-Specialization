# Cleaning and Tokenization

Before implementing any natural language processing algorithm, you might want to clean the data and tokenize it. Here are a few things to keep track of when handling your data.

![](ur0mznE0QzO9Js5xNNMz-Q_7c33998c0cd94306b1d3bfe38e9d9e22_Screen-Shot-2021-03-29-at-10.33.16-AM.png)

You can clean data using python as follows: 

![](xEZ1XH0_RQ-GdVx9P9UP8w_a1fafb1bfca94bb283ec91fb96623465_Screen-Shot-2021-03-29-at-10.36.20-AM.png)

You can add as many conditions as you want in the lines corresponding to the green rectangle above. 

