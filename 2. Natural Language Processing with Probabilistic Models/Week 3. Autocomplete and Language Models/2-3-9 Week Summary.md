# Week Summary

This week you learned the following concepts

* N-Grams and probabilities
* Approximate sentence probability from N-Grams
* Build a language model from a corpus
* Fix missing information
* Out of vocabulary words with <UNK>
* Missing N-Gram in corpus with smoothing, backoff and interpolation
* Evaluate language model with perplexity
* Coding assignment! 